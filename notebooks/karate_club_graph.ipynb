{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjecturing on Nodes in the Karate Club Graph\n",
    "\n",
    "This notebook demonstrates how the TxGraffiti algorithm can be used to generate conjectures about the nodes in a graph. In particular, we will use the famous Karate Club graph, a well-known social network that has been widely studied in network science. The graph represents friendships among members of a karate club, with nodes representing members and edges representing friendships.\n",
    "\n",
    "We will calculate various numerical and boolean properties of the nodes in the graph, and use TxGraffiti to conjecture relationships between these properties.\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RandyRDavila/AI-discovery-in-mathematics-with-TxGraffiti/blob/main/notebooks/karate_club_graph.ipynb)\n",
    "\n",
    "## Properties of the Nodes\n",
    "\n",
    "We will calculate the following properties for each node:\n",
    "- Degree: The number of edges connected to the node.\n",
    "- Clustering Coefficient: A measure of the degree to which nodes in a graph tend to cluster together.\n",
    "- Betweenness Centrality: A measure of centrality in a graph based on shortest paths.\n",
    "- Closeness Centrality: A measure of centrality in a graph that is defined as the reciprocal of the sum of the shortest path distances from a node to all other nodes.\n",
    "- Eigenvector Centrality: A measure of the influence of a node in a network.\n",
    "- PageRank: A measure of the importance of a node in a graph, used by the Google search engine.\n",
    "- Is Leader: A boolean property indicating whether a node is a leader in the karate club.\n",
    "- Is Peripheral: A boolean property indicating whether a node has a low degree.\n",
    "- Is Central: A boolean property indicating whether a node has a high betweenness centrality.\n",
    "\n",
    "We will then use these properties to generate conjectures about the relationships between the numerical properties, optionally conditioned on the boolean properties.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from pulp import *\n",
    "from fractions import Fraction\n",
    "from itertools import combinations\n",
    "\n",
    "# Load the Karate Club graph\n",
    "G = nx.karate_club_graph()\n",
    "\n",
    "# Compute numerical properties\n",
    "degree = dict(G.degree())\n",
    "clustering_coefficient = nx.clustering(G)\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "closeness_centrality = nx.closeness_centrality(G)\n",
    "eigenvector_centrality = nx.eigenvector_centrality(G)\n",
    "pagerank = nx.pagerank(G)\n",
    "\n",
    "# Create boolean properties\n",
    "leader_nodes = {0, 33}  # Known leaders in the Karate Club\n",
    "is_leader = {node: (node in leader_nodes) for node in G.nodes()}\n",
    "is_peripheral = {node: (degree[node] <= 2) for node in G.nodes()}\n",
    "is_central = {node: (betweenness_centrality[node] > np.median(list(betweenness_centrality.values()))) for node in G.nodes()}\n",
    "\n",
    "# Create a DataFrame\n",
    "data = []\n",
    "for node in G.nodes():\n",
    "    data.append([\n",
    "        degree[node],\n",
    "        clustering_coefficient[node],\n",
    "        betweenness_centrality[node],\n",
    "        closeness_centrality[node],\n",
    "        eigenvector_centrality[node],\n",
    "        pagerank[node],\n",
    "        is_leader[node],\n",
    "        is_peripheral[node],\n",
    "        is_central[node]\n",
    "    ])\n",
    "\n",
    "columns = [\n",
    "    \"degree\", \"clustering_coefficient\", \"betweenness_centrality\", \"closeness_centrality\",\n",
    "    \"eigenvector_centrality\", \"pagerank\", \"is_leader\", \"is_peripheral\", \"is_central\"\n",
    "]\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Define the hypothesis, conclusion, and conjecture classes\n",
    "class Hypothesis:\n",
    "    def __init__(self, statements):\n",
    "        self.statements = statements\n",
    "\n",
    "class LinearConclusion:\n",
    "    def __init__(self, target, inequality, slope, other, intercept):\n",
    "        self.target = target\n",
    "        self.inequality = inequality\n",
    "        self.slope = slope\n",
    "        self.other = other\n",
    "        self.intercept = intercept\n",
    "\n",
    "class LinearConjecture:\n",
    "    def __init__(self, hypothesis, conclusion, symbol, touch, type=\"node\"):\n",
    "        self.hypothesis = hypothesis\n",
    "        self.conclusion = conclusion\n",
    "        self.symbol = symbol\n",
    "        self.touch = touch\n",
    "        self.type = type\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.hypothesis.statements:\n",
    "            hypothesis_str = \" and \".join([f\"{self.symbol} is {h}\" for h in self.hypothesis.statements])\n",
    "            return (f\"For any {self.type} {self.symbol}, if {hypothesis_str}, then \"\n",
    "                    f\"{self.conclusion.target}({self.symbol}) {self.conclusion.inequality} \"\n",
    "                    f\"{self.conclusion.slope}*{self.conclusion.other}({self.symbol}) + \"\n",
    "                    f\"{self.conclusion.intercept}, with equality on {self.touch} instances.\")\n",
    "        else:\n",
    "            return (f\"For any {self.type} {self.symbol}, \"\n",
    "                    f\"{self.conclusion.target}({self.symbol}) {self.conclusion.inequality} \"\n",
    "                    f\"{self.conclusion.slope}*{self.conclusion.other}({self.symbol}) + \"\n",
    "                    f\"{self.conclusion.intercept}, with equality on {self.touch} instances.\")\n",
    "\n",
    "    def get_sharp_objects(self, df):\n",
    "        X = df[self.conclusion.other].to_numpy()\n",
    "        Y = df[self.conclusion.target].to_numpy()\n",
    "        sharp_indices = df[np.isclose(Y, float(self.conclusion.slope) * X + float(self.conclusion.intercept))].index\n",
    "        return df.loc[sharp_indices]\n",
    "\n",
    "    def calculate_distances(self, df):\n",
    "        X = df[self.conclusion.other].to_numpy()\n",
    "        Y = df[self.conclusion.target].to_numpy()\n",
    "        distances = np.abs(Y - (float(self.conclusion.slope) * X + float(self.conclusion.intercept)))\n",
    "        return distances\n",
    "\n",
    "def make_upper_linear_conjecture(df, target, other, hypothesis, symbol=\"N\"):\n",
    "    for hyp in hypothesis:\n",
    "        df = df[df[hyp] == True]\n",
    "    X = df[other].to_numpy()\n",
    "    Y = df[target].to_numpy()\n",
    "\n",
    "    prob = LpProblem(\"UpperBoundConjecture\", LpMinimize)\n",
    "    w = LpVariable(\"w\")\n",
    "    b = LpVariable(\"b\")\n",
    "\n",
    "    prob += lpSum([w * x + b - y for x, y in zip(X, Y)])\n",
    "\n",
    "    for x, y in zip(X, Y):\n",
    "        prob += w * x + b - y >= 0\n",
    "\n",
    "    prob.solve(PULP_CBC_CMD(msg=0))  # Suppress solver output\n",
    "\n",
    "    if w.varValue is None or b.varValue is None:\n",
    "        return None\n",
    "\n",
    "    m = Fraction(w.varValue).limit_denominator(10)\n",
    "    b = Fraction(b.varValue).limit_denominator(10)\n",
    "    if m == 0:\n",
    "        return None  # Skip trivial conjectures\n",
    "\n",
    "    touch = np.sum(np.isclose(Y, float(m) * X + float(b)))\n",
    "\n",
    "    hypothesis = Hypothesis(hypothesis)\n",
    "    conclusion = LinearConclusion(target, \"<=\", m, other, b)\n",
    "\n",
    "    return LinearConjecture(hypothesis, conclusion, symbol, touch)\n",
    "\n",
    "def make_lower_linear_conjecture(df, target, other, hypothesis, symbol=\"N\"):\n",
    "    for hyp in hypothesis:\n",
    "        df = df[df[hyp] == True]\n",
    "    X = df[other].to_numpy()\n",
    "    Y = df[target].to_numpy()\n",
    "\n",
    "    prob = LpProblem(\"LowerBoundConjecture\", LpMaximize)\n",
    "    w = LpVariable(\"w\")\n",
    "    b = LpVariable(\"b\")\n",
    "\n",
    "    prob += lpSum([w * x + b - y for x, y in zip(X, Y)])\n",
    "\n",
    "    for x, y in zip(X, Y):\n",
    "        prob += w * x + b - y <= 0\n",
    "\n",
    "    prob.solve(PULP_CBC_CMD(msg=0))  # Suppress solver output\n",
    "\n",
    "    if w.varValue is None or b.varValue is None:\n",
    "        return None\n",
    "\n",
    "    m = Fraction(w.varValue).limit_denominator(10)\n",
    "    b = Fraction(b.varValue).limit_denominator(10)\n",
    "    if m == 0:\n",
    "        return None  # Skip trivial conjectures\n",
    "\n",
    "    touch = np.sum(np.isclose(Y, float(m) * X + float(b)))\n",
    "\n",
    "    hypothesis = Hypothesis(hypothesis)\n",
    "    conclusion = LinearConclusion(target, \">=\", m, other, b)\n",
    "\n",
    "    return LinearConjecture(hypothesis, conclusion, symbol, touch)\n",
    "\n",
    "def make_all_upper_linear_conjectures(df, target, others, properties):\n",
    "    conjectures = []\n",
    "    for other in others:\n",
    "        for k in range(4):  # Considering hypotheses of none, one, two, and three boolean properties\n",
    "            for prop_comb in combinations(properties, k):\n",
    "                if other != target:\n",
    "                    conjecture = make_upper_linear_conjecture(df, target, other, prop_comb)\n",
    "                    if conjecture:\n",
    "                        conjectures.append(conjecture)\n",
    "    return conjectures\n",
    "\n",
    "def make_all_lower_linear_conjectures(df, target, others, properties):\n",
    "    conjectures = []\n",
    "    for other in others:\n",
    "        for k in range(4):  # Considering hypotheses of none, one, two, and three boolean properties\n",
    "            for prop_comb in combinations(properties, k):\n",
    "                if other != target:\n",
    "                    conjecture = make_lower_linear_conjecture(df, target, other, prop_comb)\n",
    "                    if conjecture:\n",
    "                        conjectures.append(conjecture)\n",
    "    return conjectures\n",
    "\n",
    "def sort_by_touch_number(conjectures):\n",
    "    return sorted(conjectures, key=lambda x: x.touch, reverse=True)\n",
    "\n",
    "def apply_theo_heuristic(conjectures):\n",
    "    filtered_conjectures = []\n",
    "    for conj_1 in conjectures:\n",
    "        is_general = True\n",
    "        for conj_2 in filtered_conjectures:\n",
    "            if (conj_1.conclusion.slope == conj_2.conclusion.slope and\n",
    "                conj_1.conclusion.intercept == conj_2.conclusion.intercept and\n",
    "                conj_1.conclusion.inequality == conj_2.conclusion.inequality and\n",
    "                set(conj_1.hypothesis.statements).issubset(set(conj_2.hypothesis.statements))):\n",
    "                is_general = False\n",
    "                break\n",
    "        if is_general:\n",
    "            filtered_conjectures.append(conj_1)\n",
    "    return filtered_conjectures\n",
    "\n",
    "def apply_static_dalmatian_heuristic(df, conjectures):\n",
    "    filtered_conjectures = []\n",
    "    for conj in conjectures:\n",
    "        conj_distances = conj.calculate_distances(df)\n",
    "        keep_conj = True\n",
    "        for other_conj in filtered_conjectures:\n",
    "            other_distances = other_conj.calculate_distances(df)\n",
    "            if np.all(conj_distances >= other_distances):\n",
    "                keep_conj = False\n",
    "                break\n",
    "        if keep_conj:\n",
    "            filtered_conjectures.append(conj)\n",
    "    return filtered_conjectures\n",
    "\n",
    "def txgraffiti_conjecture_generation(df, targets, invariants, properties):\n",
    "    conjectures = []\n",
    "    for target in targets:\n",
    "        upper_conjectures = make_all_upper_linear_conjectures(df, target, invariants, properties)\n",
    "        lower_conjectures = make_all_lower_linear_conjectures(df, target, invariants, properties)\n",
    "        conjectures += upper_conjectures + lower_conjectures\n",
    "\n",
    "    conjectures = sort_by_touch_number(conjectures)\n",
    "    conjectures = apply_theo_heuristic(conjectures)\n",
    "    conjectures = apply_static_dalmatian_heuristic(df, conjectures)\n",
    "\n",
    "    return conjectures\n",
    "\n",
    "# Define the targets, invariants, and properties\n",
    "numerical_columns = [\"degree\", \"clustering_coefficient\", \"betweenness_centrality\", \"closeness_centrality\", \"eigenvector_centrality\", \"pagerank\"]\n",
    "boolean_columns = [\"is_leader\", \"is_peripheral\", \"is_central\"]\n",
    "\n",
    "# User selects some subset of the numerical and boolean columns\n",
    "selected_targets = [\"degree\", \"clustering_coefficient\"]\n",
    "selected_invariants = [\"betweenness_centrality\", \"closeness_centrality\"]\n",
    "selected_properties = [\"is_leader\", \"is_peripheral\"]\n",
    "\n",
    "# Generate conjectures using the TxGraffiti algorithm\n",
    "conjectures = txgraffiti_conjecture_generation(df, selected_targets, selected_invariants, selected_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjecture 1.  For any node N, clustering_coefficient(N) <= -19/10*betweenness_centrality(N) + 1, with equality on 11 instances. \n",
      "\n",
      "Conjecture 2.  For any node N, if N is is_peripheral, then clustering_coefficient(N) <= -8257/7*betweenness_centrality(N) + 1, with equality on 10 instances. \n",
      "\n",
      "Conjecture 3.  For any node N, if N is is_peripheral, then degree(N) >= 8257/7*betweenness_centrality(N) + 1, with equality on 2 instances. \n",
      "\n",
      "Conjecture 4.  For any node N, degree(N) >= 240/7*betweenness_centrality(N) + 1, with equality on 1 instances. \n",
      "\n",
      "Conjecture 5.  For any node N, clustering_coefficient(N) >= 1/3*betweenness_centrality(N) + 0, with equality on 1 instances. \n",
      "\n",
      "Conjecture 6.  For any node N, degree(N) <= 571/8*betweenness_centrality(N) + 36/7, with equality on 0 instances. \n",
      "\n",
      "Conjecture 7.  For any node N, if N is is_leader, then degree(N) <= -15/2*betweenness_centrality(N) + 135/7, with equality on 0 instances. \n",
      "\n",
      "Conjecture 8.  For any node N, degree(N) <= 113/2*closeness_centrality(N) + -141/10, with equality on 0 instances. \n",
      "\n",
      "Conjecture 9.  For any node N, if N is is_leader, then degree(N) <= -369/7*closeness_centrality(N) + 46, with equality on 0 instances. \n",
      "\n",
      "Conjecture 10.  For any node N, degree(N) >= 74/5*closeness_centrality(N) + -31/7, with equality on 0 instances. \n",
      "\n",
      "Conjecture 11.  For any node N, if N is is_leader, then clustering_coefficient(N) <= 3/10*betweenness_centrality(N) + 0, with equality on 0 instances. \n",
      "\n",
      "Conjecture 12.  For any node N, if N is is_leader, then clustering_coefficient(N) <= 21/10*closeness_centrality(N) + -1, with equality on 0 instances. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the generated conjectures\n",
    "for i, conj in enumerate(conjectures[:20]):\n",
    "    print(f\"Conjecture {i+1}. \", conj, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
